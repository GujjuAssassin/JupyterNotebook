{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as k\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import ConvLSTM2D,LSTM,Dense,Bidirectional, TimeDistributed,Conv1D,Flatten,MaxPool1D\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_steps = 25\n",
    "n_features=1\n",
    "\n",
    "def split_seq(data, n_steps=3):\n",
    "    x,y = [],[]\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        if(i+n_steps >= len(data)):\n",
    "            break\n",
    "        x.append(data[i:i+n_steps])\n",
    "        y.append(data[i+n_steps])\n",
    "    \n",
    "    return x,y\n",
    "def gen_data(n_samples, func):\n",
    "    return np.array([func(i) for i in range(n_samples)])\n",
    "        \n",
    "            \n",
    "    \n",
    "f = lambda x: x**2\n",
    "n_samples=450\n",
    "data = gen_data(n_samples,f)\n",
    "x = len(data)\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(data)\n",
    "plt.show()\n",
    "trainx, trainy = split_seq(data, n_steps)\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425\n"
     ]
    }
   ],
   "source": [
    "print(len(trainx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(425, 25, 1)\n"
     ]
    }
   ],
   "source": [
    "x=(np.asarray(trainx))\n",
    "\n",
    "x = x.reshape((x.shape[0],x.shape[1],n_features))\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(425,)\n"
     ]
    }
   ],
   "source": [
    "y = np.array(trainy)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_steps, n_features))))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 3s 281ms/step - loss: 47556.0469 - val_loss: 166231.9219\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 2s 213ms/step - loss: 47214.6367 - val_loss: 165309.6406\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 2s 191ms/step - loss: 46959.2578 - val_loss: 163416.3281\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 2s 220ms/step - loss: 46717.2148 - val_loss: 163258.2656\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 3s 242ms/step - loss: 46345.7578 - val_loss: 162686.5938\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 3s 236ms/step - loss: 46239.4688 - val_loss: 161114.5156\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 3s 263ms/step - loss: 45600.0000 - val_loss: 163118.8438\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 2s 216ms/step - loss: 46888.4180 - val_loss: 160369.7812\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 3s 298ms/step - loss: 46544.3438 - val_loss: 158009.4062\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 4s 334ms/step - loss: 44747.6406 - val_loss: 153732.3125\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 3s 305ms/step - loss: 41642.9805 - val_loss: 138372.8750\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 2s 196ms/step - loss: 37717.0977 - val_loss: 122811.3281\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 3s 296ms/step - loss: 32808.7891 - val_loss: 105372.5156\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 3s 238ms/step - loss: 29519.4785 - val_loss: 103222.7031\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 2s 177ms/step - loss: 27650.3066 - val_loss: 103455.9844\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 2s 200ms/step - loss: 28163.5410 - val_loss: 93067.3125\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 3s 296ms/step - loss: 24942.9824 - val_loss: 83526.5859\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 4s 373ms/step - loss: 23952.0176 - val_loss: 83905.7500\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 3s 245ms/step - loss: 24207.7109 - val_loss: 79325.9375\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 3s 292ms/step - loss: 24019.4902 - val_loss: 102377.9062\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 4s 367ms/step - loss: 33694.2070 - val_loss: 156351.2969\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 4s 342ms/step - loss: 40326.0547 - val_loss: 114668.7422\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 3s 311ms/step - loss: 41883.9531 - val_loss: 168977.5312\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 3s 237ms/step - loss: 49306.6133 - val_loss: 169514.5000\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 2s 205ms/step - loss: 44878.7188 - val_loss: 150527.5625\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 3s 307ms/step - loss: 42598.6016 - val_loss: 148530.5469\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 4s 358ms/step - loss: 42508.5117 - val_loss: 142073.3594\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 3s 238ms/step - loss: 40331.7852 - val_loss: 139469.4844\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 39752.4570 - val_loss: 138230.3281\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 2s 217ms/step - loss: 39306.0664 - val_loss: 141042.1250\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 4s 344ms/step - loss: 39837.4453 - val_loss: 139865.6719\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 5s 434ms/step - loss: 38723.6758 - val_loss: 135129.7500\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 4s 319ms/step - loss: 38017.5625 - val_loss: 133870.0469\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 2s 203ms/step - loss: 37542.2031 - val_loss: 127309.3672\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 3s 270ms/step - loss: 35670.4648 - val_loss: 120897.2344\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 3s 253ms/step - loss: 35064.4805 - val_loss: 117887.0469\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 3s 295ms/step - loss: 33196.9375 - val_loss: 111603.7891\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 2s 191ms/step - loss: 31970.5098 - val_loss: 113667.8828\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 2s 199ms/step - loss: 30894.9609 - val_loss: 103811.7422\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 2s 176ms/step - loss: 28834.9531 - val_loss: 94995.9766\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 3s 310ms/step - loss: 25667.8730 - val_loss: 87636.0781\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 3s 313ms/step - loss: 41421.4805 - val_loss: 142120.8281\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 3s 258ms/step - loss: 27108.5273 - val_loss: 76468.7422\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 3s 249ms/step - loss: 27244.5977 - val_loss: 90668.6562\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 2s 210ms/step - loss: 25175.7109 - val_loss: 88523.1094\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 4s 331ms/step - loss: 25880.6914 - val_loss: 94031.5312\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 4s 363ms/step - loss: 30048.6113 - val_loss: 98100.7500\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 4s 374ms/step - loss: 23866.5469 - val_loss: 74151.1094\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 3s 273ms/step - loss: 22802.1523 - val_loss: 77787.9141\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 4s 371ms/step - loss: 21962.8008 - val_loss: 76690.0469\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 4s 375ms/step - loss: 21774.2910 - val_loss: 76286.0156\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 3s 244ms/step - loss: 22910.2676 - val_loss: 79835.7188\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 4s 343ms/step - loss: 24009.0508 - val_loss: 76799.7734\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 4s 338ms/step - loss: 22285.4395 - val_loss: 73735.3750\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 3s 257ms/step - loss: 21315.2930 - val_loss: 71674.2500\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 2s 211ms/step - loss: 20667.2949 - val_loss: 68239.9062\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 2s 205ms/step - loss: 20271.1230 - val_loss: 68107.0859\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 2s 201ms/step - loss: 19751.7637 - val_loss: 66379.8984\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 3s 285ms/step - loss: 19513.1191 - val_loss: 64359.7070\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 2s 190ms/step - loss: 19356.3418 - val_loss: 63754.0430\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 2s 202ms/step - loss: 19168.4492 - val_loss: 63707.7656\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 3s 246ms/step - loss: 19120.9375 - val_loss: 63915.0664\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 2s 215ms/step - loss: 19157.8789 - val_loss: 63054.7773\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 2s 197ms/step - loss: 18735.5625 - val_loss: 61312.2578\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 3s 317ms/step - loss: 18021.2480 - val_loss: 59535.3047\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 2s 194ms/step - loss: 17694.0508 - val_loss: 58009.3984\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 3s 248ms/step - loss: 17253.0762 - val_loss: 59381.8359\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 2s 209ms/step - loss: 17319.8633 - val_loss: 59522.0703\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 2s 214ms/step - loss: 18170.3574 - val_loss: 60532.6016\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 2s 199ms/step - loss: 18251.2402 - val_loss: 61364.2344\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 3s 312ms/step - loss: 18090.7910 - val_loss: 60884.5117\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 3s 242ms/step - loss: 17648.6289 - val_loss: 60004.1406\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 2s 192ms/step - loss: 17883.7090 - val_loss: 82009.8672\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 2s 193ms/step - loss: 49444.0078 - val_loss: 68941.7656\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 2s 212ms/step - loss: 20462.0312 - val_loss: 71914.1562\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 3s 279ms/step - loss: 21932.1289 - val_loss: 70657.1875\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 2s 202ms/step - loss: 21273.2676 - val_loss: 68460.2812\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 2s 224ms/step - loss: 20846.5742 - val_loss: 67712.8438\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 2s 223ms/step - loss: 20043.4082 - val_loss: 68056.8828\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 3s 304ms/step - loss: 19773.5918 - val_loss: 63479.8359\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 2s 192ms/step - loss: 18967.2246 - val_loss: 62766.1719\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 2s 207ms/step - loss: 18466.4902 - val_loss: 60840.8828\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 2s 187ms/step - loss: 18174.6621 - val_loss: 60554.7891\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 2s 188ms/step - loss: 18595.4980 - val_loss: 63099.2227\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 2s 195ms/step - loss: 18252.0488 - val_loss: 61856.3242\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 2s 206ms/step - loss: 17486.1719 - val_loss: 64227.2812\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 3s 252ms/step - loss: 18646.6797 - val_loss: 63094.6016\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 4s 319ms/step - loss: 17801.1855 - val_loss: 59073.7344\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 2s 206ms/step - loss: 17167.9023 - val_loss: 60016.7539\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 2s 199ms/step - loss: 17028.8125 - val_loss: 58091.8281\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 3s 253ms/step - loss: 16536.4082 - val_loss: 56716.5078\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 3s 269ms/step - loss: 15919.7852 - val_loss: 55195.0938\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 2s 200ms/step - loss: 15173.7334 - val_loss: 53321.3750\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 3s 274ms/step - loss: 14848.4219 - val_loss: 52136.3594\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 2s 206ms/step - loss: 14963.1299 - val_loss: 52088.5117\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 2s 203ms/step - loss: 14955.6855 - val_loss: 52859.4766\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 2s 218ms/step - loss: 15236.0322 - val_loss: 52121.0234\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 3s 250ms/step - loss: 15053.1592 - val_loss: 51157.1758\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 2s 213ms/step - loss: 14418.2441 - val_loss: 51586.3633\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 3s 233ms/step - loss: 14740.3467 - val_loss: 50811.0234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13d97e44f48>"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "test = np.array([f(i) for i in range(10)])\n",
    "test = test.reshape(1, test.shape[0],n_features)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: [70.95574]\n"
     ]
    }
   ],
   "source": [
    "def test(start):\n",
    "    test = np.array([f(i) for i in range(start,start+n_steps,1)])\n",
    "    test = test.reshape(1, test.shape[0],n_features)\n",
    "#     print(test.shape)\n",
    "    pred = model.predict(test)\n",
    "    actual = f(start+n_steps)\n",
    "    \n",
    "    diff=np.round(abs((pred[0][0]-actual)/abs(actual)),3)\n",
    "#     print(pred[0][0],actual,diff*100)\n",
    "    return diff\n",
    "\n",
    "def accuracy(n_samples, seed=1000):\n",
    "    d = 0\n",
    "    for i in range(n_samples):\n",
    "        d+=test(np.random.randint(seed))\n",
    "    print(\"Accuracy: {}\".format((1-(d/(n_samples+1)))*100))\n",
    "\n",
    "accuracy(1000)\n",
    "# print(np.random.randint(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def make_sequence(data,n_steps):\n",
    "    x,y = [],[]\n",
    "    for i in range(len(data)):\n",
    "        if i+n_steps >= len(data):\n",
    "            break\n",
    "        x.append(data[i:i+n_steps])\n",
    "        y.append(data[i+n_steps])\n",
    "    return np.array(x),np.array(y)\n",
    "\n",
    "def gen_data(n_samples, mapping_func,n_steps):\n",
    "    return make_sequence([mapping_func(i) for i in range(n_sample)],n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-286-fad5074a8157>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmapping_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgen_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_sample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmapping_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mn_sequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-285-0a1d97666c6d>\u001b[0m in \u001b[0;36mgen_data\u001b[1;34m(n_samples, mapping_func, n_steps)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgen_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmapping_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmake_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmapping_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-285-0a1d97666c6d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgen_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmapping_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmake_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmapping_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-286-fad5074a8157>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#data has 20 steps but we split each step into 2 subsequence to feed our CNN LSTM hybrid model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmapping_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgen_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_sample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmapping_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mn_sequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "n_sequence=2\n",
    "n_sample = 500\n",
    "n_steps = 10 \n",
    "n_features = 1\n",
    "#data has 20 steps but we split each step into 2 subsequence to feed our CNN LSTM hybrid model\n",
    "\n",
    "mapping_func = lambda x: x(np.sin(x)+np.cos(x))\n",
    "\n",
    "x,y=gen_data(n_sample,mapping_func,n_steps*n_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 20)\n",
      "(480, 2, 10)\n"
     ]
    }
   ],
   "source": [
    "#[samples, sequences, timesteps, features]\n",
    "print(x.shape)\n",
    "xtrain=x.reshape((x.shape[0], n_sequence, n_steps))\n",
    "print(xtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 2, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "xtrain=np.expand_dims(xtrain,axis=-1)\n",
    "print(xtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  0]\n",
      "  [ 10]\n",
      "  [ 20]\n",
      "  [ 30]\n",
      "  [ 40]\n",
      "  [ 50]\n",
      "  [ 60]\n",
      "  [ 70]\n",
      "  [ 80]\n",
      "  [ 90]]\n",
      "\n",
      " [[100]\n",
      "  [110]\n",
      "  [120]\n",
      "  [130]\n",
      "  [140]\n",
      "  [150]\n",
      "  [160]\n",
      "  [170]\n",
      "  [180]\n",
      "  [190]]] 200\n"
     ]
    }
   ],
   "source": [
    "print(xtrain[0],y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "#Model with CNN + LSTM hybrid model input [n_samples,n_sequence,n_steps,n_features]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(Conv1D(64,1,activation='relu'), input_shape=(None,n_steps,n_features)))\n",
    "model.add(TimeDistributed(MaxPool1D(pool_size=2)))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_3 (TimeDist (None, None, 9, 64)       192       \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, None, 4, 64)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, None, 256)         0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50)                61400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 61,643\n",
      "Trainable params: 61,643\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 1581.8040 - val_loss: 1772.2614\n",
      "Epoch 2/300\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 1532.2297 - val_loss: 3349.7632\n",
      "Epoch 3/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1528.6515 - val_loss: 2443.4583\n",
      "Epoch 4/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1534.7565 - val_loss: 1990.1931\n",
      "Epoch 5/300\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1528.7098 - val_loss: 1261.3478\n",
      "Epoch 6/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1560.6578 - val_loss: 3940.1333\n",
      "Epoch 7/300\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 1536.9875 - val_loss: 2106.9231\n",
      "Epoch 8/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1517.5822 - val_loss: 1379.1313\n",
      "Epoch 9/300\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 1495.3792 - val_loss: 2126.5957\n",
      "Epoch 10/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1502.0043 - val_loss: 663.2286\n",
      "Epoch 11/300\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1569.6471 - val_loss: 1490.7277\n",
      "Epoch 12/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1498.1479 - val_loss: 2908.1807\n",
      "Epoch 13/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1468.1886 - val_loss: 2188.2227\n",
      "Epoch 14/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1434.3661 - val_loss: 1982.9844\n",
      "Epoch 15/300\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1426.6444 - val_loss: 2223.2661\n",
      "Epoch 16/300\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1407.1814 - val_loss: 2773.1243\n",
      "Epoch 17/300\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1407.7567 - val_loss: 2322.5029\n",
      "Epoch 18/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1395.5690 - val_loss: 1366.6710\n",
      "Epoch 19/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1430.1027 - val_loss: 2630.3259\n",
      "Epoch 20/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 4902.6055 - val_loss: 1092.0864\n",
      "Epoch 21/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 3941.5762 - val_loss: 8141.2153\n",
      "Epoch 22/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 2146.1218 - val_loss: 8052.2603\n",
      "Epoch 23/300\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 1685.9370 - val_loss: 6811.4116\n",
      "Epoch 24/300\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 1635.2968 - val_loss: 4994.6196\n",
      "Epoch 25/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 1419.4525 - val_loss: 1574.5302\n",
      "Epoch 26/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1412.6017 - val_loss: 3789.9548\n",
      "Epoch 27/300\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 1401.7782 - val_loss: 3738.7183\n",
      "Epoch 28/300\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 1397.1453 - val_loss: 4445.3384\n",
      "Epoch 29/300\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 1415.7321 - val_loss: 2314.1479\n",
      "Epoch 30/300\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 1367.1707 - val_loss: 1503.7057\n",
      "Epoch 31/300\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 1381.0374 - val_loss: 1950.5608\n",
      "Epoch 32/300\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 1349.5443 - val_loss: 2430.7266\n",
      "Epoch 33/300\n",
      "13/13 [==============================] - ETA: 0s - loss: 1342.67 - 0s 30ms/step - loss: 1342.6772 - val_loss: 2871.7725\n",
      "Epoch 34/300\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 1359.2007 - val_loss: 2141.6152\n",
      "Epoch 35/300\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 1324.3871 - val_loss: 880.5471\n",
      "Epoch 36/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1337.1991 - val_loss: 3151.5195\n",
      "Epoch 37/300\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 1308.6432 - val_loss: 4283.8647\n",
      "Epoch 38/300\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 1290.2875 - val_loss: 3144.0859\n",
      "Epoch 39/300\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 1292.2360 - val_loss: 2512.0781\n",
      "Epoch 40/300\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 1284.3745 - val_loss: 1170.2605\n",
      "Epoch 41/300\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 1296.8737 - val_loss: 3057.6458\n",
      "Epoch 42/300\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 1266.0638 - val_loss: 3724.3740\n",
      "Epoch 43/300\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 1295.3868 - val_loss: 1820.3716\n",
      "Epoch 44/300\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 1249.0387 - val_loss: 1805.3870\n",
      "Epoch 45/300\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 1245.8845 - val_loss: 1909.6163\n",
      "Epoch 46/300\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 1229.7716 - val_loss: 511.8424\n",
      "Epoch 47/300\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 1249.8073 - val_loss: 3020.5085\n",
      "Epoch 48/300\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 1283.7898 - val_loss: 2994.9927\n",
      "Epoch 49/300\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 1208.4485 - val_loss: 2255.2800\n",
      "Epoch 50/300\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 1184.9200 - val_loss: 1207.5391\n",
      "Epoch 51/300\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 1216.6880 - val_loss: 4332.2769\n",
      "Epoch 52/300\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 1209.1992 - val_loss: 3176.8521\n",
      "Epoch 53/300\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 1184.0037 - val_loss: 1658.1906\n",
      "Epoch 54/300\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 1144.1212 - val_loss: 725.7612\n",
      "Epoch 55/300\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 1176.6461 - val_loss: 2299.3538\n",
      "Epoch 56/300\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 1128.0743 - val_loss: 2216.8044\n",
      "Epoch 57/300\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 1136.4897 - val_loss: 1569.5959\n",
      "Epoch 58/300\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 1107.7014 - val_loss: 1580.0000\n",
      "Epoch 59/300\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 1110.9232 - val_loss: 2673.5530\n",
      "Epoch 60/300\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 1095.5620 - val_loss: 2697.1167\n",
      "Epoch 61/300\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 1123.3197 - val_loss: 646.4580\n",
      "Epoch 62/300\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 1118.1077 - val_loss: 1195.1593\n",
      "Epoch 63/300\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1088.1952 - val_loss: 1992.8342\n",
      "Epoch 64/300\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1052.7788 - val_loss: 1112.8528\n",
      "Epoch 65/300\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1047.0186 - val_loss: 1892.2166\n",
      "Epoch 66/300\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1043.6034 - val_loss: 3367.1289\n",
      "Epoch 67/300\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1081.3577 - val_loss: 346.3871\n",
      "Epoch 68/300\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1081.9041 - val_loss: 2365.5098\n",
      "Epoch 69/300\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1044.0135 - val_loss: 1954.2650\n",
      "Epoch 70/300\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 1000.6422 - val_loss: 375.3180\n",
      "Epoch 71/300\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1082.0016 - val_loss: 2051.7131\n",
      "Epoch 72/300\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 991.9216 - val_loss: 3198.0776\n",
      "Epoch 73/300\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 1019.0694 - val_loss: 923.2589\n",
      "Epoch 74/300\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 974.9130 - val_loss: 1987.5154\n",
      "Epoch 75/300\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 951.0297 - val_loss: 1670.3529\n",
      "Epoch 76/300\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 968.2411 - val_loss: 1750.8589\n",
      "Epoch 77/300\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 925.4217 - val_loss: 2167.2671\n",
      "Epoch 78/300\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 942.1780 - val_loss: 2064.9299\n",
      "Epoch 79/300\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 947.2863 - val_loss: 814.0051\n",
      "Epoch 80/300\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 934.1942 - val_loss: 1516.3994\n",
      "Epoch 81/300\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 900.9537 - val_loss: 1202.2313\n",
      "Epoch 82/300\n",
      "13/13 [==============================] - ETA: 0s - loss: 881.762 - 0s 25ms/step - loss: 881.7620 - val_loss: 328.7616\n",
      "Epoch 83/300\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 933.5823 - val_loss: 3060.4443\n",
      "Epoch 84/300\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 885.1135 - val_loss: 1463.5709\n",
      "Epoch 85/300\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 872.4875 - val_loss: 2281.4485\n",
      "Epoch 86/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 847.6802 - val_loss: 1787.1289\n",
      "Epoch 87/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 839.0959 - val_loss: 1072.4912\n",
      "Epoch 88/300\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 836.8793 - val_loss: 1369.6683\n",
      "Epoch 89/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 34637.8789 - val_loss: 720495.5625\n",
      "Epoch 90/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 72544.8750 - val_loss: 142263.3281\n",
      "Epoch 91/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 13731.8477 - val_loss: 27830.8047\n",
      "Epoch 92/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 4159.9619 - val_loss: 4418.2231\n",
      "Epoch 93/300\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1925.0953 - val_loss: 3268.5386\n",
      "Epoch 94/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1163.9767 - val_loss: 3713.9580\n",
      "Epoch 95/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 973.4161 - val_loss: 1928.2144\n",
      "Epoch 96/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 917.3008 - val_loss: 1646.0658\n",
      "Epoch 97/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 923.9657 - val_loss: 1616.2806\n",
      "Epoch 98/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 910.5627 - val_loss: 1670.8678\n",
      "Epoch 99/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 925.8804 - val_loss: 1742.7924\n",
      "Epoch 100/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 929.4844 - val_loss: 834.8051\n",
      "Epoch 101/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 941.2465 - val_loss: 1204.7456\n",
      "Epoch 102/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 888.3123 - val_loss: 1013.1104\n",
      "Epoch 103/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 887.9999 - val_loss: 1594.3533\n",
      "Epoch 104/300\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 884.8222 - val_loss: 2687.8584\n",
      "Epoch 105/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 885.2902 - val_loss: 1753.9526\n",
      "Epoch 106/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 861.6583 - val_loss: 914.5972\n",
      "Epoch 107/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 868.8354 - val_loss: 1638.6908\n",
      "Epoch 108/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 854.0642 - val_loss: 1949.3906\n",
      "Epoch 109/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 853.1932 - val_loss: 1404.2102\n",
      "Epoch 110/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 853.9964 - val_loss: 1356.5758\n",
      "Epoch 111/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 854.7395 - val_loss: 1122.2192\n",
      "Epoch 112/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 858.4862 - val_loss: 1766.5942\n",
      "Epoch 113/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 854.0504 - val_loss: 1918.3053\n",
      "Epoch 114/300\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 827.6667 - val_loss: 1206.6951\n",
      "Epoch 115/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 816.9316 - val_loss: 1156.4122\n",
      "Epoch 116/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 815.6385 - val_loss: 917.2298\n",
      "Epoch 117/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 815.7918 - val_loss: 1404.9800\n",
      "Epoch 118/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 794.4606 - val_loss: 523.6639\n",
      "Epoch 119/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 858.0369 - val_loss: 1406.7372\n",
      "Epoch 120/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 814.9188 - val_loss: 2298.3838\n",
      "Epoch 121/300\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 819.7202 - val_loss: 2750.1123\n",
      "Epoch 122/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 790.8351 - val_loss: 1465.9861\n",
      "Epoch 123/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 779.5682 - val_loss: 1835.2717\n",
      "Epoch 124/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 841.4894 - val_loss: 3856.0850\n",
      "Epoch 125/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 822.2590 - val_loss: 2133.5100\n",
      "Epoch 126/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 759.5415 - val_loss: 2533.8086\n",
      "Epoch 127/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 768.7684 - val_loss: 1808.9833\n",
      "Epoch 128/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 756.4334 - val_loss: 955.7961\n",
      "Epoch 129/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 751.0521 - val_loss: 994.2722\n",
      "Epoch 130/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 741.3615 - val_loss: 2847.4246\n",
      "Epoch 131/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 780.0389 - val_loss: 2391.6589\n",
      "Epoch 132/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 752.3791 - val_loss: 859.0726\n",
      "Epoch 133/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 723.7308 - val_loss: 1359.2310\n",
      "Epoch 134/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 712.8152 - val_loss: 668.8138\n",
      "Epoch 135/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 719.8094 - val_loss: 2739.6223\n",
      "Epoch 136/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 721.6259 - val_loss: 1186.2288\n",
      "Epoch 137/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 703.1712 - val_loss: 784.1558\n",
      "Epoch 138/300\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 715.2413 - val_loss: 348.4408\n",
      "Epoch 139/300\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 723.6177 - val_loss: 1762.5131\n",
      "Epoch 140/300\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 712.7167 - val_loss: 1526.9246\n",
      "Epoch 141/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 688.7181 - val_loss: 1306.2397\n",
      "Epoch 142/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 673.8159 - val_loss: 1573.5275\n",
      "Epoch 143/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 671.5505 - val_loss: 1362.6617\n",
      "Epoch 144/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 668.8465 - val_loss: 550.6330\n",
      "Epoch 145/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 661.5331 - val_loss: 633.2119\n",
      "Epoch 146/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 657.8711 - val_loss: 1626.5393\n",
      "Epoch 147/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 646.6689 - val_loss: 901.6130\n",
      "Epoch 148/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 648.4111 - val_loss: 973.3443\n",
      "Epoch 149/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 632.4775 - val_loss: 1211.4943\n",
      "Epoch 150/300\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 639.0276 - val_loss: 1095.3071\n",
      "Epoch 151/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 648.2563 - val_loss: 164616.0156\n",
      "Epoch 152/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 19815.3984 - val_loss: 18889.9844\n",
      "Epoch 153/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 23ms/step - loss: 5952.8252 - val_loss: 3454.6724\n",
      "Epoch 154/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1544.5752 - val_loss: 4392.3096\n",
      "Epoch 155/300\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1079.1851 - val_loss: 3642.2388\n",
      "Epoch 156/300\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 660.8447 - val_loss: 653.4115\n",
      "Epoch 157/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 641.6503 - val_loss: 1081.2368\n",
      "Epoch 158/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 606.3554 - val_loss: 1440.6744\n",
      "Epoch 159/300\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 609.6617 - val_loss: 539.8365\n",
      "Epoch 160/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 606.5132 - val_loss: 1193.2168\n",
      "Epoch 161/300\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 586.6519 - val_loss: 788.6086\n",
      "Epoch 162/300\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 583.8946 - val_loss: 675.8290\n",
      "Epoch 163/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 578.9146 - val_loss: 1462.3011\n",
      "Epoch 164/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1668.7191 - val_loss: 52181.2461\n",
      "Epoch 165/300\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 3580.1826 - val_loss: 76964.6719\n",
      "Epoch 166/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 33633.9609 - val_loss: 99730.1328\n",
      "Epoch 167/300\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 21063.1406 - val_loss: 2858.8276\n",
      "Epoch 168/300\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 7216.5586 - val_loss: 191.4559\n",
      "Epoch 169/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 2832.9019 - val_loss: 198.9117\n",
      "Epoch 170/300\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 1331.2131 - val_loss: 94.7262\n",
      "Epoch 171/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1016.7890 - val_loss: 158.1426\n",
      "Epoch 172/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1026.6232 - val_loss: 361.0159\n",
      "Epoch 173/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 958.4621 - val_loss: 1288.5667\n",
      "Epoch 174/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 913.8411 - val_loss: 2489.0632\n",
      "Epoch 175/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 929.3799 - val_loss: 1743.2301\n",
      "Epoch 176/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 914.3043 - val_loss: 968.6137\n",
      "Epoch 177/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 903.0351 - val_loss: 1360.9923\n",
      "Epoch 178/300\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 910.4817 - val_loss: 943.0473\n",
      "Epoch 179/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 909.3070 - val_loss: 1384.7964\n",
      "Epoch 180/300\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 894.2172 - val_loss: 1698.5135\n",
      "Epoch 181/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 886.5392 - val_loss: 2074.8560\n",
      "Epoch 182/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 897.6163 - val_loss: 2169.8816\n",
      "Epoch 183/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 887.0851 - val_loss: 1502.1184\n",
      "Epoch 184/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 869.0036 - val_loss: 2428.2722\n",
      "Epoch 185/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 890.9364 - val_loss: 2266.4363\n",
      "Epoch 186/300\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 890.5904 - val_loss: 1702.8127\n",
      "Epoch 187/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 882.1802 - val_loss: 1198.2513\n",
      "Epoch 188/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 890.7767 - val_loss: 509.7062\n",
      "Epoch 189/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 866.6979 - val_loss: 1102.4628\n",
      "Epoch 190/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 839.7744 - val_loss: 1677.8451\n",
      "Epoch 191/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 860.3872 - val_loss: 2088.1956\n",
      "Epoch 192/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 835.2786 - val_loss: 1509.6869\n",
      "Epoch 193/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 829.1334 - val_loss: 1405.7949\n",
      "Epoch 194/300\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 819.5851 - val_loss: 1966.8342\n",
      "Epoch 195/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 826.8477 - val_loss: 1618.4685\n",
      "Epoch 196/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 816.9417 - val_loss: 873.5631\n",
      "Epoch 197/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 807.1820 - val_loss: 1845.5031\n",
      "Epoch 198/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 815.5576 - val_loss: 689.0564\n",
      "Epoch 199/300\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 808.7538 - val_loss: 984.8745\n",
      "Epoch 200/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 815.4012 - val_loss: 1737.8936\n",
      "Epoch 201/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 819.8045 - val_loss: 564.4418\n",
      "Epoch 202/300\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 810.1529 - val_loss: 360.1273\n",
      "Epoch 203/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 829.6281 - val_loss: 1181.1697\n",
      "Epoch 204/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 808.7029 - val_loss: 2547.1531\n",
      "Epoch 205/300\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 773.7502 - val_loss: 2087.6199\n",
      "Epoch 206/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 786.0003 - val_loss: 1512.0553\n",
      "Epoch 207/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 762.6942 - val_loss: 853.0560\n",
      "Epoch 208/300\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 760.3054 - val_loss: 1207.2797\n",
      "Epoch 209/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 763.9163 - val_loss: 2574.9175\n",
      "Epoch 210/300\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 793.9651 - val_loss: 1716.7202\n",
      "Epoch 211/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 741.0496 - val_loss: 854.7590\n",
      "Epoch 212/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 740.1533 - val_loss: 1357.6097\n",
      "Epoch 213/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 739.7311 - val_loss: 1100.5630\n",
      "Epoch 214/300\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 732.5953 - val_loss: 1072.8228\n",
      "Epoch 215/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 716.2123 - val_loss: 633.5510\n",
      "Epoch 216/300\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 745.1379 - val_loss: 1890.3951\n",
      "Epoch 217/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 705.9227 - val_loss: 2141.8193\n",
      "Epoch 218/300\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 708.4946 - val_loss: 528.2636\n",
      "Epoch 219/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 738.4510 - val_loss: 1254.2712\n",
      "Epoch 220/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 726.4520 - val_loss: 1551.8594\n",
      "Epoch 221/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 688.6440 - val_loss: 1048.2969\n",
      "Epoch 222/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 682.9615 - val_loss: 1131.6163\n",
      "Epoch 223/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 679.4763 - val_loss: 1355.5278\n",
      "Epoch 224/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 688.2446 - val_loss: 694.9170\n",
      "Epoch 225/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 675.5798 - val_loss: 709.7057\n",
      "Epoch 226/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 698.9777 - val_loss: 2139.1348\n",
      "Epoch 227/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 681.3188 - val_loss: 1620.4028\n",
      "Epoch 228/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 653.2287 - val_loss: 641.2864\n",
      "Epoch 229/300\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 660.8591 - val_loss: 935.3673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 642.0829 - val_loss: 1230.1533\n",
      "Epoch 231/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 670.5190 - val_loss: 636.6381\n",
      "Epoch 232/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 717.6232 - val_loss: 2586.4062\n",
      "Epoch 233/300\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 728.6349 - val_loss: 100.7101\n",
      "Epoch 234/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 682.4761 - val_loss: 1520.3944\n",
      "Epoch 235/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 625.2713 - val_loss: 1249.5298\n",
      "Epoch 236/300\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 614.1343 - val_loss: 1016.7546\n",
      "Epoch 237/300\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 605.3406 - val_loss: 979.9644\n",
      "Epoch 238/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 598.5602 - val_loss: 1131.3147\n",
      "Epoch 239/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 594.7398 - val_loss: 1733.9761\n",
      "Epoch 240/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 595.9734 - val_loss: 517.1463\n",
      "Epoch 241/300\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 590.1287 - val_loss: 985.8489\n",
      "Epoch 242/300\n",
      "13/13 [==============================] - ETA: 0s - loss: 580.909 - 0s 23ms/step - loss: 580.9090 - val_loss: 1522.5525\n",
      "Epoch 243/300\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 607.2731 - val_loss: 331.1828\n",
      "Epoch 244/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 585.4134 - val_loss: 1860.1122\n",
      "Epoch 245/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 572.8468 - val_loss: 1299.8429\n",
      "Epoch 246/300\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 555.5157 - val_loss: 1223.2966\n",
      "Epoch 247/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 558.5469 - val_loss: 967.0788\n",
      "Epoch 248/300\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 548.8001 - val_loss: 800.5413\n",
      "Epoch 249/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 539.5258 - val_loss: 685.6472\n",
      "Epoch 250/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 534.8566 - val_loss: 829.1313\n",
      "Epoch 251/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 542.1724 - val_loss: 569.2881\n",
      "Epoch 252/300\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 557.2703 - val_loss: 480.5204\n",
      "Epoch 253/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 558.2851 - val_loss: 813.4908\n",
      "Epoch 254/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 541.0231 - val_loss: 19297.3789\n",
      "Epoch 255/300\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 943.3771 - val_loss: 899.4738\n",
      "Epoch 256/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 1425.5422 - val_loss: 8219.7979\n",
      "Epoch 257/300\n",
      "13/13 [==============================] - ETA: 0s - loss: 1447.10 - 0s 23ms/step - loss: 1447.1060 - val_loss: 86.7522\n",
      "Epoch 258/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 912.1135 - val_loss: 1247.8162\n",
      "Epoch 259/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 728.7143 - val_loss: 313.4792\n",
      "Epoch 260/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 565.1234 - val_loss: 1117.2456\n",
      "Epoch 261/300\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 525.6521 - val_loss: 1234.9454\n",
      "Epoch 262/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 510.7375 - val_loss: 415.4461\n",
      "Epoch 263/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 511.2832 - val_loss: 1731.7224\n",
      "Epoch 264/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 511.6250 - val_loss: 649.9431\n",
      "Epoch 265/300\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 495.9342 - val_loss: 783.4662\n",
      "Epoch 266/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 486.1066 - val_loss: 702.9359\n",
      "Epoch 267/300\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 485.6102 - val_loss: 578.4402\n",
      "Epoch 268/300\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 480.2401 - val_loss: 1021.6848\n",
      "Epoch 269/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 477.8007 - val_loss: 505.0908\n",
      "Epoch 270/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 477.9451 - val_loss: 699.7994\n",
      "Epoch 271/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 467.8087 - val_loss: 995.1371\n",
      "Epoch 272/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 459.2290 - val_loss: 459.6746\n",
      "Epoch 273/300\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 460.4958 - val_loss: 1520.6486\n",
      "Epoch 274/300\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 453.0447 - val_loss: 948.0371\n",
      "Epoch 275/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 448.1003 - val_loss: 467.7909\n",
      "Epoch 276/300\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 470.2462 - val_loss: 513.4064\n",
      "Epoch 277/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 432.4531 - val_loss: 900.6887\n",
      "Epoch 278/300\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 454.8074 - val_loss: 271.2447\n",
      "Epoch 279/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 414.9413 - val_loss: 795.0153\n",
      "Epoch 280/300\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 423.6290 - val_loss: 378.8306\n",
      "Epoch 281/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 419.4648 - val_loss: 423.9845\n",
      "Epoch 282/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 411.6785 - val_loss: 825.6560\n",
      "Epoch 283/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 389.7607 - val_loss: 1455.0537\n",
      "Epoch 284/300\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 386.2635 - val_loss: 1851.7693\n",
      "Epoch 285/300\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 383.4053 - val_loss: 1617.6997\n",
      "Epoch 286/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 378.4514 - val_loss: 307.1508\n",
      "Epoch 287/300\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 431.4208 - val_loss: 3.6271\n",
      "Epoch 288/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 405.0493 - val_loss: 400.5050\n",
      "Epoch 289/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 347.4244 - val_loss: 37.7844\n",
      "Epoch 290/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 425.1330 - val_loss: 38.0296\n",
      "Epoch 291/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 418.2281 - val_loss: 112.8564\n",
      "Epoch 292/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 344.8350 - val_loss: 231.8287\n",
      "Epoch 293/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 318.8020 - val_loss: 1021.7245\n",
      "Epoch 294/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 346.9527 - val_loss: 55.8246\n",
      "Epoch 295/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 326.1092 - val_loss: 307.5296\n",
      "Epoch 296/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 314.1159 - val_loss: 418.0912\n",
      "Epoch 297/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 306.0158 - val_loss: 1055.7710\n",
      "Epoch 298/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 307.2119 - val_loss: 719.1903\n",
      "Epoch 299/300\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 278.6993 - val_loss: 729.8786\n",
      "Epoch 300/300\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 280.2771 - val_loss: 618.7712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x28421583908>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain,y,epochs=300,validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011883974746919015"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test(seed=1000,ns):\n",
    "    start = np.random.randint(seed)\n",
    "    testx = np.array([np.array([i*10 for i in range(start,start+(n_steps*n_sequence),1)]) for _ in range(ns)])\n",
    "    actual = testx[:,-1]\n",
    "    testx = testx.reshape((1,n_sequence,n_steps,n_features))\n",
    "    pred = model(testx)\n",
    "    actual = (start+(n_steps*n_sequence))*10\n",
    "    return abs(pred[0][0].numpy()-actual)/actual\n",
    "\n",
    "def accuray(ns):\n",
    "    s = 0\n",
    "    for i in range(ns):\n",
    "        s+=test()\n",
    "    print(1-s/100)\n",
    "    \n",
    "test()\n",
    "    # accuray(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_lst_m2d_1 (ConvLSTM2D)  (None, 1, 9, 64)          33536     \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 577       \n",
      "=================================================================\n",
      "Total params: 34,113\n",
      "Trainable params: 34,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Model with ConvLSTM2D input [n_samples,n_sequence,rows,columns,n_features]\n",
    "\n",
    "fmodel = Sequential()\n",
    "fmodel.add(ConvLSTM2D(filters=64,kernel_size=(1,2),activation='relu',input_shape=(n_sequence,1,n_steps, n_features)))\n",
    "fmodel.add(Flatten())\n",
    "fmodel.add(Dense(1))\n",
    "fmodel.compile(optimizer='adam', loss='mse')\n",
    "fmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 2, 1, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "shape = xtrain.shape\n",
    "xtrain1=xtrain.reshape(shape[0],shape[1],1,shape[2],shape[3])\n",
    "print(xtrain1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 123.9355 - val_loss: 966.6169\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 144.5487 - val_loss: 988.9753\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 147.5407 - val_loss: 862.3262\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 128.2309 - val_loss: 1111.1146\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 95.3067 - val_loss: 1327.7113\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 134.0112 - val_loss: 511.3009\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 183.7360 - val_loss: 928.6046\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 170.8697 - val_loss: 3261.2429\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 199.0203 - val_loss: 1031.3666\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 104.6923 - val_loss: 1359.0139\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 89.0222 - val_loss: 700.0168\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 162.8645 - val_loss: 2268.6956\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 154.7183 - val_loss: 425.9094\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 191.9110 - val_loss: 2433.6187\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 134.3867 - val_loss: 498.6568\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 80.9226 - val_loss: 1279.5098\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 77.9996 - val_loss: 513.3062\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 89.4174 - val_loss: 1616.2233\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 85.6016 - val_loss: 493.5677\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 64.8947 - val_loss: 609.4536\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 65.8261 - val_loss: 966.1404\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 59.5703 - val_loss: 882.1779\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 75.7356 - val_loss: 1114.0381\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 58.4154 - val_loss: 857.9064\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 63.8119 - val_loss: 1171.7642\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 86.5482 - val_loss: 1040.7644\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 95.7141 - val_loss: 1077.5199\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 73.3989 - val_loss: 664.0616\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 95.5700 - val_loss: 1321.8319\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 106.5067 - val_loss: 727.3254\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 79.9891 - val_loss: 1377.5938\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 103.8162 - val_loss: 457.2087\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 154.6980 - val_loss: 946.8659\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 112.8023 - val_loss: 1084.3807\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 354.5918 - val_loss: 6971.9863\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 377.2133 - val_loss: 2118.3262\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 664.6328 - val_loss: 3810.2000\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 1090.1573 - val_loss: 1699.6656\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 3704.2297 - val_loss: 10155.3799\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 376356.7500 - val_loss: 254838.5469\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 45254.9258 - val_loss: 79346.7734\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 15476.4053 - val_loss: 37945.8945\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 4540.4810 - val_loss: 720.8562\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 12387.6924 - val_loss: 420375.7500\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 614297.6250 - val_loss: 68393.5547\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 66232.7656 - val_loss: 2593.3181\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 23464.9395 - val_loss: 3796.8059\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 8148.8247 - val_loss: 5434.6045\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 4323.4380 - val_loss: 5535.3853\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3114.1438 - val_loss: 5491.1348\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2759.7334 - val_loss: 4519.2593\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2612.4070 - val_loss: 6615.5054\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2638.5796 - val_loss: 4337.9155\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2611.7078 - val_loss: 6032.3384\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2580.4172 - val_loss: 5181.9907\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2567.3369 - val_loss: 4838.3335\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2508.6399 - val_loss: 6016.2612\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2483.8015 - val_loss: 5549.2383\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2445.6067 - val_loss: 5846.4790\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 2399.1458 - val_loss: 5747.6069\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 2368.5769 - val_loss: 5037.1870\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 2300.5884 - val_loss: 5390.6299\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 2205.9922 - val_loss: 5089.9272\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 2003.6709 - val_loss: 4151.4854\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 1808.5699 - val_loss: 5319.0835\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 1453.9354 - val_loss: 3959.7439\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 979.2270 - val_loss: 3161.1941\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 904.9402 - val_loss: 2914.6748\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 937.3138 - val_loss: 4179.8335\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 872.5833 - val_loss: 2395.8926\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 3203.3372 - val_loss: 8917.7979\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 1540.6792 - val_loss: 2002.5934\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 1062.6069 - val_loss: 4846.6655\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 930.1205 - val_loss: 4875.4507\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 766.6203 - val_loss: 1923.5172\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 708.7483 - val_loss: 3525.1345\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 687.0065 - val_loss: 1946.8654\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 699.4038 - val_loss: 4398.9536\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 629.7766 - val_loss: 1831.3281\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 582.0411 - val_loss: 3253.8486\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 611.5831 - val_loss: 2001.2582\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 616.5187 - val_loss: 2981.3535\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 548.1907 - val_loss: 1274.8446\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 549.0493 - val_loss: 2318.9541\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 456.1884 - val_loss: 1521.3444\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 344.5966 - val_loss: 2318.6257\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 280.1535 - val_loss: 1801.4521\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 224.5817 - val_loss: 1326.6118\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 184.4200 - val_loss: 1499.1188\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 168.9916 - val_loss: 1444.1520\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 154.8120 - val_loss: 1184.6211\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 148.3745 - val_loss: 1232.4177\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 153.1358 - val_loss: 1338.4546\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 143.4904 - val_loss: 1438.8854\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 147.5940 - val_loss: 1159.8062\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 157.5543 - val_loss: 1003.4229\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 151.7874 - val_loss: 1153.8473\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 119.5839 - val_loss: 951.4831\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 101.3744 - val_loss: 1110.2253\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 97.0192 - val_loss: 692.5957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x28431323cc8>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmodel.fit(xtrain1,y,epochs=100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2, 1, 10, 1)\n",
      "98.41189679982091\n"
     ]
    }
   ],
   "source": [
    "def acc(model,ns=1000):\n",
    "    seed = 10000\n",
    "    testx = np.array([(np.random.randint(100)*10)+np.array([i*10 for i in range(n_steps*n_sequence)]) for _ in range(ns)])\n",
    "    actual = testx[:,-1]+10\n",
    "    sh=np.array(model.inputs[0].get_shape().as_list())\n",
    "    sh[sh==None]=-1\n",
    "#     sh = testx.shape\n",
    "#     ins = fmodel.inputs[0].get_shape()[1:]\n",
    "    testx=testx.reshape(sh)\n",
    "    print(testx.shape)\n",
    "    prediction = model.predict(testx)\n",
    "    acc=(1-np.mean(abs(prediction[:,0]-actual)/actual))*100\n",
    "    print(acc)\n",
    "    \n",
    "acc(fmodel,100)\n",
    "# sh=np.array(model.inputs[0].get_shape().as_list())\n",
    "\n",
    "# print(sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 10  15  25]\n",
      " [ 20  25  45]\n",
      " [ 30  35  65]\n",
      " [ 40  45  85]\n",
      " [ 50  55 105]\n",
      " [ 60  65 125]\n",
      " [ 70  75 145]\n",
      " [ 80  85 165]\n",
      " [ 90  95 185]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#mulitvariate data \n",
    "#Example of multivariate data\n",
    "#[10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "#[15, 25, 35, 45, 55, 65, 75, 85, 95]\n",
    "limit=1000\n",
    "n_steps=10\n",
    "in_seq1 = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "in_seq2 = np.array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
    "out_seq = in_seq1+in_seq2\n",
    "in_seq1=in_seq1.reshape((len(in_seq1),1))\n",
    "in_seq2=in_seq2.reshape((len(in_seq1),1))\n",
    "out_seq=out_seq.reshape((len(out_seq),1))\n",
    "dataset = np.hstack((in_seq1,in_seq2,out_seq))\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-04f088450e31>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
